{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1cRzlrxVvmICpeyc1DSG7iPnGusurmVZs","authorship_tag":"ABX9TyOIOc1h/77hQgRXsYU0RNOa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["\n","**cycleGAN model**\n","\n","Based on the code by Jason Brownlee from his blogs on https://machinelearningmastery.com/\n","I am adapting his code to various applications but original credit goes to Jason. \n","\n","The model uses instance normalization layer:\n","Normalize the activations of the previous layer at each step,\n","i.e. applies a transformation that maintains the mean activation\n","close to 0 and the activation standard deviation close to 1.\n","Standardizes values on each output feature map rather than across features in a batch. ​\n","\n","Download instance normalization code from here: \n","\n","https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/layers/normalization/instancenormalization.py\n","\n","Or install keras_contrib using guidelines here: \n","\n","https://github.com/keras-team/keras-contrib \n"],"metadata":{"id":"NBdhDhkxXfgQ"}},{"cell_type":"markdown","source":[],"metadata":{"id":"ilqbDFscv55L"}},{"cell_type":"code","source":["!pip install tensorflow==2.4.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4VPiXLxlxobm","outputId":"b640bf38-d4f5-44db-ebf5-c66c900cec9b","executionInfo":{"status":"ok","timestamp":1678201075305,"user_tz":-330,"elapsed":63730,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==2.4.1\n","  Downloading tensorflow-2.4.1-cp38-cp38-manylinux2010_x86_64.whl (394.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.4/394.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (3.19.6)\n","Collecting gast==0.3.3\n","  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n","Collecting absl-py~=0.10\n","  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wrapt~=1.12.1\n","  Downloading wrapt-1.12.1.tar.gz (27 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (3.3.0)\n","Collecting keras-preprocessing~=1.1.2\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (1.15.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (0.2.0)\n","Collecting numpy~=1.19.2\n","  Downloading numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting grpcio~=1.32.0\n","  Downloading grpcio-1.32.0-cp38-cp38-manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (0.38.4)\n","Collecting h5py~=2.10.0\n","  Downloading h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.5.0,>=2.4.0\n","  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.0/462.0 KB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting flatbuffers~=1.12.0\n","  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","Collecting termcolor~=1.1.0\n","  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (2.11.2)\n","Collecting typing-extensions~=3.7.4\n","  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (1.6.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.16.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.2.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.25.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.4.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (6.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.26.14)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (4.0.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.4->tensorflow==2.4.1) (2.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.15.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.2.2)\n","Building wheels for collected packages: termcolor, wrapt\n","  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4849 sha256=b43cb28d9941def5f79e247f7115135229c1b00f36d88f1605d30d64be0efa40\n","  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n","  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=78576 sha256=bb3933e82650f0edf8abee1da678365e525b486f7b484382344d7f6aac0d963c\n","  Stored in directory: /root/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n","Successfully built termcolor wrapt\n","Installing collected packages: wrapt, typing-extensions, termcolor, tensorflow-estimator, flatbuffers, numpy, grpcio, gast, absl-py, keras-preprocessing, h5py, tensorflow\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.15.0\n","    Uninstalling wrapt-1.15.0:\n","      Successfully uninstalled wrapt-1.15.0\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","  Attempting uninstall: termcolor\n","    Found existing installation: termcolor 2.2.0\n","    Uninstalling termcolor-2.2.0:\n","      Successfully uninstalled termcolor-2.2.0\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.11.0\n","    Uninstalling tensorflow-estimator-2.11.0:\n","      Successfully uninstalled tensorflow-estimator-2.11.0\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 23.1.21\n","    Uninstalling flatbuffers-23.1.21:\n","      Successfully uninstalled flatbuffers-23.1.21\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.22.4\n","    Uninstalling numpy-1.22.4:\n","      Successfully uninstalled numpy-1.22.4\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.51.3\n","    Uninstalling grpcio-1.51.3:\n","      Successfully uninstalled grpcio-1.51.3\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.4.0\n","    Uninstalling gast-0.4.0:\n","      Successfully uninstalled gast-0.4.0\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 1.4.0\n","    Uninstalling absl-py-1.4.0:\n","      Successfully uninstalled absl-py-1.4.0\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.11.0\n","    Uninstalling tensorflow-2.11.0:\n","      Successfully uninstalled tensorflow-2.11.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","xarray-einstats 0.5.1 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","pydantic 1.10.5 requires typing-extensions>=4.2.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n","jaxlib 0.4.4+cuda11.cudnn82 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","jax 0.4.4 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.32.0 which is incompatible.\n","google-cloud-bigquery 3.4.2 requires grpcio<2.0dev,>=1.47.0, but you have grpcio 1.32.0 which is incompatible.\n","cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.19.5 which is incompatible.\n","cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n","bokeh 2.4.3 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed absl-py-0.15.0 flatbuffers-1.12 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 keras-preprocessing-1.1.2 numpy-1.19.5 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras "],"metadata":{"id":"fIopt0Y1xzMz","executionInfo":{"status":"ok","timestamp":1678201077995,"user_tz":-330,"elapsed":2696,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["print(tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qx8vFxmbxbQi","executionInfo":{"status":"ok","timestamp":1678201077995,"user_tz":-330,"elapsed":5,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}},"outputId":"ae5bbeb5-7805-4f08-e4ce-568467d2b25d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["2.4.1\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"8r3M8khkWuOC","executionInfo":{"status":"ok","timestamp":1678201077995,"user_tz":-330,"elapsed":3,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}}},"outputs":[],"source":["from random import random\n","from numpy import load\n","from numpy import zeros\n","from numpy import ones\n","from numpy import asarray\n","from numpy.random import randint\n","from tensorflow.keras.optimizers import Adam\n","#from keras.optimizers import Adam\n","from tensorflow.keras.initializers import RandomNormal\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input\n","#from tensorflow.keras.models import Input\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import Conv2DTranspose\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import Concatenate"]},{"cell_type":"code","source":["#for installing \n","!pip install keras==2.3.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xvw6k0mgagSA","executionInfo":{"status":"ok","timestamp":1678201086283,"user_tz":-330,"elapsed":8291,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}},"outputId":"bbbf22b9-cce5-4c88-f07b-3ae5b6f20419"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras==2.3.1\n","  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.8/377.8 KB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras==2.3.1) (1.19.5)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.8/dist-packages (from keras==2.3.1) (1.1.2)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.8/dist-packages (from keras==2.3.1) (1.10.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from keras==2.3.1) (6.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras==2.3.1) (2.10.0)\n","Collecting keras-applications>=1.0.6\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from keras==2.3.1) (1.15.0)\n","Installing collected packages: keras-applications, keras\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.11.0\n","    Uninstalling keras-2.11.0:\n","      Successfully uninstalled keras-2.11.0\n","Successfully installed keras-2.3.1 keras-applications-1.0.8\n"]}]},{"cell_type":"code","source":["#!pip install git+https://www.github.com/keras-team/keras-contrib.git\n","#from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization"],"metadata":{"id":"-dxzBwQxakZy","executionInfo":{"status":"ok","timestamp":1678201086285,"user_tz":-330,"elapsed":7,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Cyclegans"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ARZMhmIzcF1I","executionInfo":{"status":"ok","timestamp":1678201086285,"user_tz":-330,"elapsed":6,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}},"outputId":"86c21137-7da1-42e3-aadd-60c5ae51cc92"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Cyclegans\n"]}]},{"cell_type":"code","source":["from instancenorm import InstanceNormalization"],"metadata":{"id":"5Vzfs3DZcUgb","executionInfo":{"status":"ok","timestamp":1678201087731,"user_tz":-330,"elapsed":1450,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from matplotlib import pyplot"],"metadata":{"id":"HK2to0qvZPuQ","executionInfo":{"status":"ok","timestamp":1678201087731,"user_tz":-330,"elapsed":2,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# discriminator model (70x70 patchGAN)\n","# C64-C128-C256-C512\n","#After the last layer, conv to 1-dimensional output, followed by a Sigmoid function.  \n","# The “axis” argument is set to -1 for instance norm. to ensure that features are normalized per feature map.\n","def define_discriminator(image_shape):\n","\t# weight initialization\n","\tinit = RandomNormal(stddev=0.02)\n","\t# source image input\n","\tin_image = Input(shape=image_shape)\n","\t# C64: 4x4 kernel Stride 2x2\n","\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n","\td = LeakyReLU(alpha=0.2)(d)\n","\t# C128: 4x4 kernel Stride 2x2\n","\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n","\td = InstanceNormalization(axis=-1)(d)\n","\td = LeakyReLU(alpha=0.2)(d)\n","\t# C256: 4x4 kernel Stride 2x2\n","\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n","\td = InstanceNormalization(axis=-1)(d)\n","\td = LeakyReLU(alpha=0.2)(d)\n","\t# C512: 4x4 kernel Stride 2x2 \n","    # Not in the original paper. Comment this block if you want.\n","\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n","\td = InstanceNormalization(axis=-1)(d)\n","\td = LeakyReLU(alpha=0.2)(d)\n","\t# second last output layer : 4x4 kernel but Stride 1x1\n","\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n","\td = InstanceNormalization(axis=-1)(d)\n","\td = LeakyReLU(alpha=0.2)(d)\n","\t# patch output\n","\tpatch_out = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n","\t# define model\n","\tmodel = Model(in_image, patch_out)\n","\t# compile model\n","    #The model is trained with a batch size of one image and Adam opt. \n","    #with a small learning rate and 0.5 beta. \n","    #The loss for the discriminator is weighted by 50% for each model update.\n","    #This slows down changes to the discriminator relative to the generator model during training.\n","\tmodel.compile(loss='mse', optimizer=Adam(lr=0.0002, beta_1=0.5), loss_weights=[0.5])\n","\treturn model"],"metadata":{"id":"2JK1WIxWchIY","executionInfo":{"status":"ok","timestamp":1678201087731,"user_tz":-330,"elapsed":2,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# generator a resnet block to be used in the generator\n","# residual block that contains two 3 × 3 convolutional layers with the same number of filters on both layers.\n","def resnet_block(n_filters, input_layer):\n","\t# weight initialization\n","\tinit = RandomNormal(stddev=0.02)\n","\t# first convolutional layer\n","\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(input_layer)\n","\tg = InstanceNormalization(axis=-1)(g)\n","\tg = Activation('relu')(g)\n","\t# second convolutional layer\n","\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(g)\n","\tg = InstanceNormalization(axis=-1)(g)\n","\t# concatenate merge channel-wise with input layer\n","\tg = Concatenate()([g, input_layer])\n","\treturn g"],"metadata":{"id":"LMdMYt6hcl8a","executionInfo":{"status":"ok","timestamp":1678201143154,"user_tz":-330,"elapsed":581,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# define the  generator model - encoder-decoder type architecture\n","\n","#c7s1-k denote a 7×7 Convolution-InstanceNorm-ReLU layer with k filters and stride 1. \n","#dk denotes a 3 × 3 Convolution-InstanceNorm-ReLU layer with k filters and stride 2.\n","# Rk denotes a residual block that contains two 3 × 3 convolutional layers\n","# uk denotes a 3 × 3 fractional-strided-Convolution InstanceNorm-ReLU layer with k filters and stride 1/2\n","\n","#The network with 6 residual blocks consists of:\n","#c7s1-64,d128,d256,R256,R256,R256,R256,R256,R256,u128,u64,c7s1-3\n","\n","#The network with 9 residual blocks consists of:\n","#c7s1-64,d128,d256,R256,R256,R256,R256,R256,R256,R256,R256,R256,u128, u64,c7s1-3\n","\n","def define_generator(image_shape, n_resnet=9):\n","\t# weight initialization\n","\tinit = RandomNormal(stddev=0.02)\n","\t# image input\n","\tin_image = Input(shape=image_shape)\n","\t# c7s1-64\n","\tg = Conv2D(64, (7,7), padding='same', kernel_initializer=init)(in_image)\n","\tg = InstanceNormalization(axis=-1)(g)\n","\tg = Activation('relu')(g)\n","\t# d128\n","\tg = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n","\tg = InstanceNormalization(axis=-1)(g)\n","\tg = Activation('relu')(g)\n","\t# d256\n","\tg = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n","\tg = InstanceNormalization(axis=-1)(g)\n","\tg = Activation('relu')(g)\n","\t# R256\n","\tfor _ in range(n_resnet):\n","\t\tg = resnet_block(256, g)\n","\t# u128\n","\tg = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n","\tg = InstanceNormalization(axis=-1)(g)\n","\tg = Activation('relu')(g)\n","\t# u64\n","\tg = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n","\tg = InstanceNormalization(axis=-1)(g)\n","\tg = Activation('relu')(g)\n","\t# c7s1-3\n","\tg = Conv2D(3, (7,7), padding='same', kernel_initializer=init)(g)\n","\tg = InstanceNormalization(axis=-1)(g)\n","\tout_image = Activation('tanh')(g)\n","\t# define model\n","\tmodel = Model(in_image, out_image)\n","\treturn model"],"metadata":{"id":"LRvQ4xxAcpUq","executionInfo":{"status":"ok","timestamp":1678201143838,"user_tz":-330,"elapsed":0,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# def custom_loss(generated_image):\n","#   # converting to gray scale\n","#   gray = cv2.cvtColor(generated_image[0], cv2.COLOR_BGR2GRAY)\n","#   # remove noise\n","#   img = cv2.GaussianBlur(gray,(3,3),0)\n","#   # convolute with proper kernels\n","#   sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)  #x\n","#   sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)  #y\n","#   #calculating the magnitude and angle\n","#   magnitude = np.sqrt(sobelx**2.0 + sobely**2.0)\n","#   angle = np.arctan2(sobely, sobelx) * (180 / np.pi)\n","#   #Calculate sum of pixel intensities (number of nonzero matrix elements).\n","#   sumIntensities = np.sum(np.sum(magnitude))\n","#   #Number of pixels, whose intensity value is greater than a threshold in Sobel edge image.\n","#   numberEdgels = np.count_nonzero(magnitude)\n","#   #Calculate Entropy of enhanced image.\n","#   p = cv2.calcHist([img],[0],None,[256],[0,256])\n","#   entropy = -np.sum(np.dot(p[0],np.log2(p[0])))\n","#   #Compute objective function which tells us about the quality of the input enhanced image.\n","#   a = np.log(np.log(sumIntensities))\n","#   b = numberEdgels/np.dot(img[0], img[1])\n","#   oFit = np.dot(np.dot(a, b), entropy)\n","  \n","#   return oFit"],"metadata":{"id":"tUdhS8yKCgNG","executionInfo":{"status":"ok","timestamp":1678201144932,"user_tz":-330,"elapsed":1,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# define a composite model for updating generators by adversarial and cycle loss\n","#We define a composite model that will be used to train each generator separately. \n","def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n","\t# Make the generator of interest trainable as we will be updating these weights.\n","    #by keeping other models constant.\n","    #Remember that we use this same function to train both generators,\n","    #one generator at a time. \n","\tg_model_1.trainable = True\n","\t# mark discriminator and second generator as non-trainable\n","\td_model.trainable = False\n","\tg_model_2.trainable = False\n","    \n","\t# adversarial loss\n","\tinput_gen = Input(shape=image_shape)\n","\tgen1_out = g_model_1(input_gen)\n","\toutput_d = d_model(gen1_out)\n","\t# identity loss\n","\tinput_id = Input(shape=image_shape)\n","\toutput_id = g_model_1(input_id)\n","\t# cycle loss - forward\n","\toutput_f = g_model_2(gen1_out)\n","\t# cycle loss - backward\n","\tgen2_out = g_model_2(input_id)\n","\toutput_b = g_model_1(gen2_out)\n","    \n","\t# define model graph\n","\tmodel = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n","\t\n","  # define the optimizer\n","\topt = Adam(lr=0.0002, beta_1=0.5)\n","\t# compile model with weighting of least squares loss and L1 loss\n","\tmodel.compile(loss=['mse', 'mae', 'mae', 'mae'], \n","               loss_weights=[1, 5, 10, 10], optimizer=opt)\n","\treturn model"],"metadata":{"id":"FAmW5Ly1cze0","executionInfo":{"status":"ok","timestamp":1678201146173,"user_tz":-330,"elapsed":3,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# load and prepare training images\n","def load_real_samples(filename):\n","\t# load the dataset\n","\tdata = load(filename)\n","\t# unpack arrays\n","\tX1, X2 = data['arr_0'], data['arr_1']\n","\t# scale from [0,255] to [-1,1]\n","\tX1 = (X1 - 127.5) / 127.5\n","\tX2 = (X2 - 127.5) / 127.5\n","\treturn [X1, X2]"],"metadata":{"id":"cabXxRJ8c9zR","executionInfo":{"status":"ok","timestamp":1678201146173,"user_tz":-330,"elapsed":2,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# select a batch of random samples, returns images and target\n","#Remember that for real images the label (y) is 1. \n","def generate_real_samples(dataset, n_samples, patch_shape):\n","\t# choose random instances\n","\tix = randint(0, dataset.shape[0], n_samples)\n","\t# retrieve selected images\n","\tX = dataset[ix]\n","\t# generate 'real' class labels (1)\n","\ty = ones((n_samples, patch_shape, patch_shape, 1))\n","\treturn X, y\n"],"metadata":{"id":"8OdGY_lRej1z","executionInfo":{"status":"ok","timestamp":1678201149623,"user_tz":-330,"elapsed":1,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# generate a batch of images, returns images and targets\n","#Remember that for fake images the label (y) is 0. \n","def generate_fake_samples(g_model, dataset, patch_shape):\n","\t# generate fake images\n","\tX = g_model.predict(dataset)\n","\t# create 'fake' class labels (0)\n","\ty = zeros((len(X), patch_shape, patch_shape, 1))\n","\treturn X, y"],"metadata":{"id":"uFv6tgCoelm3","executionInfo":{"status":"ok","timestamp":1678201149623,"user_tz":-330,"elapsed":1,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# periodically save the generator models to file\n","def save_models(step, g_model_AtoB, g_model_BtoA):\n","\t# save the first generator model\n","\tfilename1 = 'g_model_AtoB_%06d.h5' % (step+1)\n","\tg_model_AtoB.save(filename1)\n","\t# save the second generator model\n","\tfilename2 = 'g_model_BtoA_%06d.h5' % (step+1)\n","\tg_model_BtoA.save(filename2)\n","\tprint('>Saved: %s and %s' % (filename1, filename2))\n"],"metadata":{"id":"GpDKIfJ3ensW","executionInfo":{"status":"ok","timestamp":1678201151947,"user_tz":-330,"elapsed":2,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# periodically generate images using the save model and plot input and output images\n","def summarize_performance(step, g_model, trainX, name, n_samples=5):\n","\t# select a sample of input images\n","\tX_in, _ = generate_real_samples(trainX, n_samples, 0)\n","\t# generate translated images\n","\tX_out, _ = generate_fake_samples(g_model, X_in, 0)\n","\t# scale all pixels from [-1,1] to [0,1]\n","\tX_in = (X_in + 1) / 2.0\n","\tX_out = (X_out + 1) / 2.0\n","\t# plot real images\n","\tfor i in range(n_samples):\n","\t\tpyplot.subplot(2, n_samples, 1 + i)\n","\t\tpyplot.axis('off')\n","\t\tpyplot.imshow(X_in[i])\n","\t# plot translated image\n","\tfor i in range(n_samples):\n","\t\tpyplot.subplot(2, n_samples, 1 + n_samples + i)\n","\t\tpyplot.axis('off')\n","\t\tpyplot.imshow(X_out[i])\n","\t# save plot to file\n","\tfilename1 = '%s_generated_plot_%06d.png' % (name, (step+1))\n","\tpyplot.savefig(filename1)\n","\tpyplot.close()"],"metadata":{"id":"OnPNG-VNepc1","executionInfo":{"status":"ok","timestamp":1678201151947,"user_tz":-330,"elapsed":1,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# update image pool for fake images to reduce model oscillation\n","# update discriminators using a history of generated images \n","#rather than the ones produced by the latest generators.\n","#Original paper recommended keeping an image buffer that stores \n","#the 50 previously created images.\n","\n","def update_image_pool(pool, images, max_size=50):\n","\tselected = list()\n","\tfor image in images:\n","\t\tif len(pool) < max_size:\n","\t\t\t# stock the pool\n","\t\t\tpool.append(image)\n","\t\t\tselected.append(image)\n","\t\telif random() < 0.5:\n","\t\t\t# use image, but don't add it to the pool\n","\t\t\tselected.append(image)\n","\t\telse:\n","\t\t\t# replace an existing image and use replaced image\n","\t\t\tix = randint(0, len(pool))\n","\t\t\tselected.append(pool[ix])\n","\t\t\tpool[ix] = image\n","\treturn asarray(selected)"],"metadata":{"id":"XhVK5BYhetuZ","executionInfo":{"status":"ok","timestamp":1678201153049,"user_tz":-330,"elapsed":2,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["\n","# train cyclegan models\n","def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset, epochs=1):\n","\t# define properties of the training run\n","\tn_epochs, n_batch, = epochs, 1  #batch size fixed to 1 as suggested in the paper\n","\t# determine the output square shape of the discriminator\n","\tn_patch = d_model_A.output_shape[1]\n","\t# unpack dataset\n","\ttrainA, trainB = dataset\n","\t# prepare image pool for fake images\n","\tpoolA, poolB = list(), list()\n","\t# calculate the number of batches per training epoch\n","\tbat_per_epo = int(len(trainA) / n_batch)\n","\t# calculate the number of training iterations\n","\tn_steps = bat_per_epo * n_epochs\n","    \n","\t# manually enumerate epochs\n","\tfor i in range(n_steps):\n","\t\t# select a batch of real samples from each domain (A and B)\n","\t\tX_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n","\t\tX_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n","\t\t# generate a batch of fake samples using both B to A and A to B generators.\n","\t\tX_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n","\t\tX_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n","\t\t# update fake images in the pool. Remember that the paper suggstes a buffer of 50 images\n","\t\tX_fakeA = update_image_pool(poolA, X_fakeA)\n","\t\tX_fakeB = update_image_pool(poolB, X_fakeB)\n","        \n","\t\t# update generator B->A via the composite model\n","\t\tg_loss2, _, _, _, _  = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n","\t\t# update discriminator for A -> [real/fake]\n","\t\tdA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n","\t\tdA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n","\t\t\n","    # update generator A->B via the composite model\n","\t\tg_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n","\t\t# update discriminator for B -> [real/fake]\n","\t\tdB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n","\t\tdB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n","\t\t\n","        # summarize performance\n","        #Since our batch size =1, the number of iterations would be same as the size of our dataset.\n","        #In one epoch you'd have iterations equal to the number of images.\n","        #If you have 100 images then 1 epoch would be 100 iterations\n","\t\tprint('Iteration>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))\n","\t\t# evaluate the model performance periodically\n","        #If batch size (total images)=100, performance will be summarized after every 75th iteration.\n","\t\tif (i+1) % (bat_per_epo * 1) == 0:\n","\t\t\t# plot A->B translation\n","\t\t\tsummarize_performance(i, g_model_AtoB, trainA, 'AtoB')\n","\t\t\t# plot B->A translation\n","\t\t\tsummarize_performance(i, g_model_BtoA, trainB, 'BtoA')\n","\t\tif (i+1) % (bat_per_epo * 5) == 0:\n","\t\t\t# save the models\n","            # #If batch size (total images)=100, model will be saved after \n","            #every 75th iteration x 5 = 375 iterations.\n","\t\t\tsave_models(i, g_model_AtoB, g_model_BtoA)"],"metadata":{"id":"I_irmVtHez50","executionInfo":{"status":"ok","timestamp":1678201154487,"user_tz":-330,"elapsed":2,"user":{"displayName":"DAKSHI GOEL","userId":"04553446645191165615"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ezBZjrSmgtx2"},"execution_count":null,"outputs":[]}]}